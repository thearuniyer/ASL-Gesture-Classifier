# gesture-predictor
ASL (AMERICAN SIGN LANGUAGE) Gesture prediction

The project contains the following files:
1.	keypoints.json: Extracts the keypoints of body parts from the frames of the videos.
2.	convert_to_csv.py: Converts the json file of keypoints to itâ€™s csv equivalent
3.	asl_feat_preprocessing_final.py: Calculates the positions of the body parts w.r.t nose and removes the unnecessary attributes for further analysis.
4.	asl_feat_extracxn_final.py: Implements feature extraction techniques to obtain the 1st, 2nd,3rd degree FFT & PSD coefficients, autocorrelation coefficients with lags, and other statistical properties. 
5.	asl_model_final.py: Trains, validates and tests ML models on the dataset
6.	data_X.txt: The dataset obtained after analysis and data wrangling.
7.	data_Y.txt: The labels for data_X.
8.	app.py: Server program that delivers predicted results for the passed json file on POST.
The app.py program was tested using POSTMAN as the client.  
Signs for buy, communicate, fun, hope, mother and really were considered for this work. The models have been pickled and can be found in the models folder.
The server url is : http://18.223.185.34:80/
